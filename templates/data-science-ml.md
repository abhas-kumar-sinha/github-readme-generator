# Customer Churn Prediction using Machine Learning

A comprehensive data science project that analyzes customer behavior patterns and predicts churn probability using ensemble methods (Random Forest, XGBoost, LightGBM). This project includes full exploratory data analysis, feature engineering, model comparison, and deployment-ready prediction pipeline.

**Project Status**: ‚úÖ Completed | üìä Accuracy: 86.3% | üéØ AUC-ROC: 0.91

## üìã Table of Contents

- [Overview](#overview)
- [Business Problem](#business-problem)
- [Dataset](#dataset)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Methodology](#methodology)
- [Results](#results)
- [Model Deployment](#model-deployment)
- [Future Work](#future-work)

## üéØ Overview

### What is This Project About?

Customer churn (the rate at which customers stop doing business with a company) is a critical metric for subscription-based businesses. This project builds a machine learning solution to:

1. **Predict** which customers are likely to churn in the next month
2. **Identify** key factors driving customer churn
3. **Provide** actionable insights for retention strategies
4. **Enable** proactive customer outreach programs

### Key Achievements

- Achieved **86.3% accuracy** in predicting customer churn
- Identified top 5 churn drivers: contract type, tenure, monthly charges, tech support, payment method
- Reduced false negatives by 35% compared to logistic regression baseline
- Built production-ready prediction pipeline with FastAPI

### Technologies Used

- **Languages**: Python 3.10
- **ML Libraries**: scikit-learn, XGBoost, LightGBM, CatBoost
- **Data Processing**: pandas, NumPy
- **Visualization**: matplotlib, seaborn, plotly
- **Notebooks**: Jupyter Lab
- **Model Tracking**: MLflow
- **Deployment**: FastAPI, Docker

## üíº Business Problem

### Context

TelcoConnect (fictional company) is experiencing a **27% annual churn rate**, which is costing the company $12M annually in lost revenue. The business needs to:

- Identify at-risk customers before they churn
- Understand why customers are leaving
- Implement targeted retention campaigns

### Project Goals

1. **Primary**: Build a model with >85% accuracy for churn prediction
2. **Secondary**: Achieve precision >0.80 to minimize wasted retention efforts
3. **Tertiary**: Provide interpretable results for business stakeholders

### Success Metrics

- **Model Performance**: Accuracy >85%, Precision >0.80, Recall >0.75
- **Business Impact**: Enable retention campaigns targeting top 10% at-risk customers
- **ROI**: Each correct prediction saves avg $1,200 in customer lifetime value

## üìä Dataset

### Source

**Dataset**: [Telco Customer Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)  
**License**: CC0: Public Domain  
**Size**: 7,043 rows √ó 21 columns

### Dataset Overview

The dataset contains customer information for a telecommunications company:

- **Customers**: 7,043 unique customer records
- **Time Period**: Q2 2020 to Q3 2020 (simulated)
- **Churn Rate**: 26.5% (1,869 churned customers)

### Features

#### Demographic Features
- `gender`: Customer gender (Male, Female)
- `SeniorCitizen`: Whether customer is 65+ (0, 1)
- `Partner`: Whether customer has a partner (Yes, No)
- `Dependents`: Whether customer has dependents (Yes, No)

#### Service Features
- `tenure`: Number of months as customer (0-72)
- `PhoneService`: Phone service subscription (Yes, No)
- `MultipleLines`: Multiple phone lines (Yes, No, No phone service)
- `InternetService`: Type of internet (DSL, Fiber optic, No)
- `OnlineSecurity`: Online security add-on (Yes, No, No internet service)
- `OnlineBackup`: Online backup add-on (Yes, No, No internet service)
- `DeviceProtection`: Device protection add-on (Yes, No, No internet service)
- `TechSupport`: Tech support add-on (Yes, No, No internet service)
- `StreamingTV`: TV streaming service (Yes, No, No internet service)
- `StreamingMovies`: Movie streaming service (Yes, No, No internet service)

#### Account Features
- `Contract`: Contract type (Month-to-month, One year, Two year)
- `PaperlessBilling`: Paperless billing (Yes, No)
- `PaymentMethod`: Payment method (Electronic check, Mailed check, Bank transfer, Credit card)
- `MonthlyCharges`: Current monthly charge ($18.25 - $118.75)
- `TotalCharges`: Total amount charged to date

#### Target Variable
- `Churn`: Whether customer churned (Yes, No)

### Data Quality

| Issue | Count | Resolution |
|:------|:------|:-----------|
| Missing Values | 11 in TotalCharges | Imputed with median |
| Duplicates | 0 | None found |
| Outliers | 3% in MonthlyCharges | Retained (legitimate high-spend customers) |
| Class Imbalance | 73.5% / 26.5% | SMOTE applied |

## üìÅ Project Structure

```
customer-churn-prediction/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                      # Original dataset
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ WA_Fn-UseC_-Telco-Customer-Churn.csv
‚îÇ   ‚îú‚îÄ‚îÄ processed/                # Cleaned and engineered data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validation.csv
‚îÇ   ‚îî‚îÄ‚îÄ external/                 # External reference data
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA.ipynb             # Exploratory Data Analysis
‚îÇ   ‚îú‚îÄ‚îÄ 02_Data_Cleaning.ipynb   # Data cleaning and preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ 03_Feature_Engineering.ipynb  # Feature creation
‚îÇ   ‚îú‚îÄ‚îÄ 04_Baseline_Models.ipynb      # Simple model benchmarks
‚îÇ   ‚îú‚îÄ‚îÄ 05_Model_Training.ipynb       # Full model training
‚îÇ   ‚îú‚îÄ‚îÄ 06_Model_Evaluation.ipynb     # Model comparison & selection
‚îÇ   ‚îî‚îÄ‚îÄ 07_Model_Interpretation.ipynb # SHAP analysis
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ load_data.py         # Data loading utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py        # Preprocessing functions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_engineering.py
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py             # Training scripts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict.py           # Prediction scripts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py          # Evaluation metrics
‚îÇ   ‚îú‚îÄ‚îÄ visualization/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plots.py             # Plotting functions
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ config.py            # Configuration
‚îÇ       ‚îî‚îÄ‚îÄ helpers.py           # Helper functions
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ random_forest_v1.pkl     # Saved model files
‚îÇ   ‚îú‚îÄ‚îÄ xgboost_v1.pkl
‚îÇ   ‚îú‚îÄ‚îÄ lightgbm_v1.pkl
‚îÇ   ‚îî‚îÄ‚îÄ final_model.pkl          # Best performing model
‚îÇ
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py               # Request/response models
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py
‚îÇ   ‚îî‚îÄ‚îÄ test_api.py
‚îÇ
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ figures/                 # Generated plots
‚îÇ   ‚îú‚îÄ‚îÄ results.md               # Model results summary
‚îÇ   ‚îî‚îÄ‚îÄ business_insights.pdf    # Executive summary
‚îÇ
‚îú‚îÄ‚îÄ deployment/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îî‚îÄ‚îÄ kubernetes/
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ environment.yml              # Conda environment
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ LICENSE
```

## üõ† Installation

### Prerequisites

- Python 3.10 or higher
- Anaconda or Miniconda (recommended)
- Jupyter Lab
- Git

### Option 1: Conda Environment (Recommended)

```bash
# Clone the repository
git clone https://github.com/username/customer-churn-prediction.git
cd customer-churn-prediction

# Create conda environment
conda env create -f environment.yml

# Activate environment
conda activate churn-analysis

# Verify installation
python -c "import sklearn, xgboost, lightgbm; print('All packages installed!')"
```

### Option 2: Virtual Environment (venv)

```bash
# Clone the repository
git clone https://github.com/username/customer-churn-prediction.git
cd customer-churn-prediction

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\\Scripts\\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Dependencies

Key packages (full list in requirements.txt):

```txt
pandas==2.0.3
numpy==1.24.3
scikit-learn==1.3.0
xgboost==2.0.0
lightgbm==4.0.0
catboost==1.2
matplotlib==3.7.2
seaborn==0.12.2
plotly==5.15.0
jupyter==1.0.0
shap==0.42.1
imbalanced-learn==0.11.0
mlflow==2.5.0
fastapi==0.100.0
uvicorn==0.23.0
```

## üöÄ Usage

### 1. Download the Dataset

```bash
# Create data directory
mkdir -p data/raw

# Download from Kaggle (requires kaggle API setup)
kaggle datasets download -d blastchar/telco-customer-churn -p data/raw

# Unzip
unzip data/raw/telco-customer-churn.zip -d data/raw
```

### 2. Run Notebooks in Order

```bash
# Start Jupyter Lab
jupyter lab

# Navigate to notebooks/ folder and run in sequence:
# 01_EDA.ipynb ‚Üí 02_Data_Cleaning.ipynb ‚Üí ... ‚Üí 07_Model_Interpretation.ipynb
```

### 3. Train Models via Scripts

```bash
# Preprocess data
python src/data/preprocess.py --input data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv --output data/processed/

# Train models
python src/models/train.py --model random_forest --data data/processed/train.csv

# Train all models with hyperparameter tuning
python src/models/train.py --model all --tune --cv 5
```

### 4. Make Predictions

```bash
# Predict on new data
python src/models/predict.py --model models/final_model.pkl --input data/new_customers.csv --output predictions.csv
```

### 5. Run API Server (for production predictions)

```bash
cd api
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Test the API
curl -X POST "http://localhost:8000/predict" \\
  -H "Content-Type: application/json" \\
  -d '{
    "gender": "Female",
    "SeniorCitizen": 0,
    "Partner": "Yes",
    "Dependents": "No",
    "tenure": 12,
    "PhoneService": "Yes",
    "InternetService": "Fiber optic",
    "Contract": "Month-to-month",
    "MonthlyCharges": 70.5
  }'
```

## üî¨ Methodology

### 1. Exploratory Data Analysis (EDA)

**Key Findings**:
- Customers with month-to-month contracts churn **42%** vs 11% for long-term contracts
- Fiber optic customers churn **41%** vs 19% for DSL customers
- Customers without tech support churn **41%** vs 15% with tech support
- Churn rate inversely correlates with tenure (strong relationship)

**Visualizations Created**:
- Churn distribution by contract type
- Correlation heatmap of numerical features
- Box plots for monthly charges by churn status
- Tenure distribution for churned vs retained

### 2. Data Preprocessing

**Steps Taken**:

1. **Missing Value Treatment**: 
   - Imputed 11 missing TotalCharges with median grouped by tenure
   
2. **Feature Encoding**:
   - Binary features (Yes/No) ‚Üí 0/1
   - Multi-class features ‚Üí One-Hot Encoding
   - Ordinal features preserved order

3. **Feature Scaling**:
   - StandardScaler for tree-based models (optional)
   - MinMaxScaler for neural networks (future work)

4. **Class Imbalance**:
   - Applied SMOTE (Synthetic Minority Over-sampling)
   - Balanced to 60/40 split

### 3. Feature Engineering

**New Features Created**:

1. **tenure_months_binned**: Categorized tenure (0-12, 13-24, 25-48, 49+)
2. **avg_monthly_spend**: TotalCharges / tenure
3. **service_count**: Total number of services subscribed
4. **has_premium_services**: Binary flag for any premium add-ons
5. **charge_tenure_ratio**: MonthlyCharges * tenure interaction
6. **contract_value**: Indicator combining contract and payment method

**Feature Importance (Top 10)**:

| Rank | Feature | Importance | Description |
|:-----|:--------|:-----------|:------------|
| 1 | tenure | 0.185 | Months as customer |
| 2 | MonthlyCharges | 0.162 | Current monthly bill |
| 3 | Contract_Month-to-month | 0.143 | Short-term contract |
| 4 | TotalCharges | 0.109 | Lifetime spending |
| 5 | InternetService_Fiber | 0.087 | Fiber internet |
| 6 | PaymentMethod_Electronic | 0.076 | Auto-pay method |
| 7 | TechSupport_No | 0.068 | No tech support |
| 8 | OnlineSecurity_No | 0.054 | No online security |
| 9 | service_count | 0.049 | Total services |
| 10 | PaperlessBilling_Yes | 0.041 | Paperless billing |

### 4. Model Training & Selection

**Models Evaluated**:

| Model | Description | Use Case |
|:------|:-----------|:---------|
| Logistic Regression | Baseline linear model | Interpretable baseline |
| Decision Tree | Simple tree-based model | Feature importance |
| Random Forest | Ensemble of trees | Robust predictions |
| XGBoost | Gradient boosting | High performance |
| LightGBM | Fast gradient boosting | Large datasets |
| CatBoost | Handles categorical data | Categorical-heavy data |

**Hyperparameter Tuning**:
- Method: Randomized Search CV (5-fold)
- Metric: ROC-AUC Score
- Iterations: 100 per model
- Computing: 12-core CPU, 4 hours

### 5. Model Evaluation

**Cross-Validation Strategy**:
- 5-Fold Stratified Cross-Validation
- Train/Val/Test Split: 60% / 20% / 20%
- Stratified to maintain class balance

**Evaluation Metrics**:
- Accuracy, Precision, Recall, F1-Score
- ROC-AUC, PR-AUC
- Confusion Matrix
- Classification Report

## üìà Results

### Model Performance Comparison

| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC | PR-AUC | Training Time |
|:------|:---------|:----------|:-------|:---------|:--------|:-------|:--------------|
| Logistic Regression | 80.1% | 0.68 | 0.62 | 0.65 | 0.82 | 0.71 | 2s |
| Decision Tree | 78.5% | 0.63 | 0.71 | 0.67 | 0.79 | 0.68 | 5s |
| Random Forest | **85.3%** | 0.82 | 0.71 | 0.76 | **0.91** | **0.84** | 45s |
| XGBoost | **86.3%** | **0.84** | 0.73 | 0.78 | 0.90 | 0.83 | 38s |
| LightGBM | 84.7% | 0.80 | **0.75** | **0.77** | 0.90 | 0.82 | 12s |
| CatBoost | 85.1% | 0.81 | 0.72 | 0.76 | 0.90 | 0.83 | 95s |

**üèÜ Best Model**: XGBoost
- **Why**: Highest accuracy (86.3%) and precision (0.84) with competitive training time
- **Runner-up**: Random Forest (more interpretable, nearly as good)

### Detailed XGBoost Results

```
Classification Report:
              precision    recall  f1-score   support

  Not Churned       0.88      0.95      0.91      1038
      Churned       0.84      0.73      0.78       371

     accuracy                           0.86      1409
    macro avg       0.86      0.84      0.85      1409
weighted avg       0.87      0.86      0.86      1409

ROC-AUC Score: 0.9037
PR-AUC Score: 0.8291
```

### Confusion Matrix (Test Set)

```
                 Predicted
                 Not Churn  Churn
Actual Not Churn    987      51
       Churn        100     271
```

**Interpretation**:
- **True Negatives**: 987 (correctly identified non-churners)
- **False Positives**: 51 (incorrectly flagged as churners)
- **False Negatives**: 100 (missed churners - **business cost**)
- **True Positives**: 271 (correctly identified churners)

### Feature Importance (SHAP Analysis)

![SHAP Summary Plot](reports/figures/shap_summary.png)

**Top Drivers of Churn**:
1. **Contract Type**: Month-to-month contracts increase churn probability by 42%
2. **Tenure**: Each additional year reduces churn risk by 15%
3. **Tech Support**: Lack of tech support increases churn by 28%
4. **Monthly Charges**: Charges >$70 increase churn by 22%
5. **Internet Type**: Fiber optic increases churn by 18% (likely due to price)

### Business Impact Simulation

Based on model predictions on 1,000 customers:

| Metric | Value | Financial Impact |
|:-------|:------|:-----------------|
| At-risk customers identified | 268 | - |
| True churners caught | 195 (73% recall) | $234,000 saved |
| False alarms | 73 | $14,600 wasted effort |
| **Net benefit** | - | **$219,400** |

**Assumption**: Retention campaign costs $200 per customer, saves $1,200 if successful

## üöÄ Model Deployment

### Local Prediction API

A FastAPI service for real-time churn predictions:

```bash
# Start the API server
cd api
uvicorn main:app --reload --port 8000

# Server runs at: http://localhost:8000
# Docs available at: http://localhost:8000/docs
```

**API Endpoints**:

1. **POST /predict** - Single customer prediction
2. **POST /predict/batch** - Batch predictions (up to 1000)
3. **GET /health** - Health check
4. **GET /model/info** - Model metadata

**Example Request**:

```python
import requests

customer_data = {
    "gender": "Female",
    "SeniorCitizen": 0,
    "Partner": "Yes",
    "Dependents": "No",
    "tenure": 12,
    "PhoneService": "Yes",
    "MultipleLines": "No",
    "InternetService": "Fiber optic",
    "OnlineSecurity": "No",
    "OnlineBackup": "No",
    "DeviceProtection": "No",
    "TechSupport": "No",
    "StreamingTV": "No",
    "StreamingMovies": "No",
    "Contract": "Month-to-month",
    "PaperlessBilling": "Yes",
    "PaymentMethod": "Electronic check",
    "MonthlyCharges": 70.35,
    "TotalCharges": 844.2
}

response = requests.post(
    "http://localhost:8000/predict",
    json=customer_data
)

print(response.json())
# Output: {"churn_probability": 0.78, "prediction": "Churn", "risk_level": "High"}
```

### Docker Deployment

```bash
# Build image
docker build -t churn-prediction-api:v1 .

# Run container
docker run -d -p 8000:8000 churn-prediction-api:v1

# Test
curl http://localhost:8000/health
```

### Production Considerations

For production deployment:

1. **Model Versioning**: Use MLflow for model registry
2. **Monitoring**: Track prediction drift with Evidently
3. **A/B Testing**: Compare model versions in production
4. **Logging**: Log all predictions for audit trail
5. **Rate Limiting**: Implement rate limits for API
6. **Authentication**: Add API key authentication

## üìä Notebooks Overview

### 01_EDA.ipynb - Exploratory Data Analysis
**Duration**: ~30 minutes  
**Output**: 15 visualizations, statistical summaries

**Key Sections**:
- Data loading and inspection
- Missing value analysis
- Distribution plots for all features
- Churn rate by demographic segments
- Correlation analysis
- Statistical tests (Chi-square, t-tests)

**Key Insights**:
- Month-to-month contracts have 3.8x higher churn
- Fiber optic customers churn 2.1x more than DSL
- Tech support reduces churn by 63%

### 02_Data_Cleaning.ipynb - Data Preprocessing
**Duration**: ~20 minutes  
**Output**: Cleaned dataset saved to `data/processed/`

**Cleaning Steps**:
1. Handle missing TotalCharges (11 rows)
2. Fix data type inconsistencies
3. Remove duplicates (none found)
4. Validate ranges and constraints
5. Create train/test split (80/20)

### 03_Feature_Engineering.ipynb - Feature Creation
**Duration**: ~25 minutes  
**Output**: 6 new engineered features

**Features Created**:
- `tenure_group`: Binned tenure categories
- `avg_monthly_charges`: TotalCharges / tenure
- `service_count`: Number of subscribed services
- `has_premium`: Flag for premium services
- `contract_payment`: Interaction feature
- `charge_ratio`: MonthlyCharges / median ratio

### 04_Baseline_Models.ipynb - Initial Models
**Duration**: ~15 minutes  
**Output**: Baseline performance benchmarks

Establishes performance baselines:
- Majority class baseline: 73.5% accuracy
- Logistic Regression: 80.1% accuracy
- Simple Decision Tree: 78.5% accuracy

### 05_Model_Training.ipynb - Advanced Models
**Duration**: ~2 hours (with hyperparameter tuning)  
**Output**: 6 trained models with optimized hyperparameters

Trains and tunes:
- Random Forest (100 trees)
- XGBoost (200 rounds)
- LightGBM (fast training)
- CatBoost (categorical handling)

### 06_Model_Evaluation.ipynb - Model Comparison
**Duration**: ~30 minutes  
**Output**: Comprehensive evaluation metrics and plots

**Evaluation Includes**:
- Performance metrics table
- ROC curves (all models)
- Precision-Recall curves
- Confusion matrices
- Cross-validation results
- Model selection justification

### 07_Model_Interpretation.ipynb - Explainability
**Duration**: ~40 minutes  
**Output**: SHAP plots, feature importance, partial dependence plots

**Analysis Includes**:
- SHAP summary plot (global feature importance)
- SHAP waterfall plots (individual predictions)
- Partial dependence plots
- Feature interaction analysis
- Business recommendations

## üí° Business Insights & Recommendations

### Top 3 Actionable Insights

#### 1. Contract Strategy üéØ
**Finding**: Month-to-month customers churn at 42% vs 11% for contract customers

**Recommendations**:
- Offer 10-15% discount for 1-year contracts
- Implement "contract transition" campaigns at months 8-10
- Provide loyalty bonuses for contract renewals
- Create hybrid "flex contracts" with lower early termination fees

**Expected Impact**: 25% reduction in month-to-month churn

#### 2. Tech Support Matters üõ†Ô∏è
**Finding**: Customers without tech support churn 63% more often

**Recommendations**:
- Include 3 months free tech support for new customers
- Proactive outreach to customers who call support >2 times
- Create self-service knowledge base to reduce friction
- Train support staff in retention techniques

**Expected Impact**: 18% reduction in overall churn

#### 3. Fiber Optic Pricing üí∞
**Finding**: Fiber customers churn 2.1x more despite premium service

**Recommendations**:
- Review fiber optic pricing strategy (currently 40% more than DSL)
- Bundle fiber with premium features (security, backup)
- Implement "price lock" guarantees for fiber customers
- Create competitive matching program

**Expected Impact**: 15% reduction in fiber optic churn

### Retention Campaign Strategy

**Target Segment**: Top 10% churn risk (based on model scores)

**Campaign Elements**:
1. **Personalized Outreach**: Email + phone call within 48 hours
2. **Custom Offers**: Based on customer's service usage
3. **Save Desk**: Dedicated retention specialists
4. **Win-back**: Re-engagement campaign for recent churners

**Budget**: $200 per customer in campaign
**Expected ROI**: 3.5x (save $1,200 per successful retention)

## üîÆ Future Work

### Short-term (Next 3 Months)
- [ ] Implement A/B testing framework for retention campaigns
- [ ] Add demographic data (location, income) if available
- [ ] Build customer lifetime value (CLV) prediction model
- [ ] Create interactive dashboard for stakeholders (Streamlit)
- [ ] Set up automated model retraining pipeline

### Medium-term (3-6 Months)
- [ ] Deep learning model (LSTM for temporal patterns)
- [ ] Causal inference analysis (why do interventions work?)
- [ ] Survival analysis for time-to-churn predictions
- [ ] Multi-model ensemble with stacking
- [ ] Real-time prediction streaming with Kafka

### Long-term (6-12 Months)
- [ ] Prescriptive analytics (optimal intervention timing)
- [ ] Customer segmentation with clustering
- [ ] Integration with CRM system (Salesforce)
- [ ] AutoML pipeline for continuous improvement
- [ ] Cost-sensitive learning (different costs for FP vs FN)

## üêõ Troubleshooting

### Common Issues

**Issue**: "TotalCharges cannot be converted to float"
```python
# Solution: Convert with error handling
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)
```

**Issue**: ImportError with XGBoost
```bash
# Solution: Install with conda instead of pip
conda install -c conda-forge xgboost
```

**Issue**: Kernel dying during model training
```python
# Solution: Reduce hyperparameter search space
param_grid = {
    'n_estimators': [50, 100],  # Reduced from [50, 100, 200]
    'max_depth': [3, 5],        # Reduced from [3, 5, 7, 10]
}
```

**Issue**: API returns 422 validation error
```bash
# Solution: Check that all required fields are included
# See api/schemas.py for complete field list
```

## üìö Additional Resources

### Learning Materials
- [Scikit-learn Documentation](https://scikit-learn.org/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [SHAP Library Guide](https://shap.readthedocs.io/)
- [Kaggle Churn Prediction Tutorial](https://www.kaggle.com/learn/intro-to-machine-learning)

### Research Papers
- Chen & Guestrin (2016): "XGBoost: A Scalable Tree Boosting System"
- Lundberg & Lee (2017): "A Unified Approach to Interpreting Model Predictions"

### Related Projects
- [Customer Segmentation with K-Means](https://github.com/example/segmentation)
- [Time Series Churn Prediction with LSTM](https://github.com/example/lstm-churn)

## ü§ù Contributing

Contributions welcome! Areas for improvement:

1. **Feature Engineering**: Propose new features
2. **Model Experimentation**: Try neural networks, ensemble methods
3. **Visualization**: Create new plots for insights
4. **Documentation**: Improve explanations
5. **Testing**: Add unit tests for preprocessing pipeline

See [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.

## üìÑ Citation

If you use this project in your research or work, please cite:

```bibtex
@misc{churn_prediction_2024,
  author = {Your Name},
  title = {Customer Churn Prediction using Machine Learning},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/username/customer-churn-prediction}
}
```

## üìß Contact

**Author**: Your Name  
**Email**: your.email@example.com  
**LinkedIn**: [Your Profile](https://linkedin.com/in/yourprofile)  
**GitHub**: [@yourusername](https://github.com/yourusername)

## üìú License

This project is licensed under the MIT License - see [LICENSE](./LICENSE) file for details.

## üôè Acknowledgments

- Dataset provided by IBM Watson Analytics
- Kaggle community for inspiration and notebooks
- Open-source ML community for amazing tools
- My university advisor for project guidance

---

**Last Updated**: December 2024  
**Project Status**: ‚úÖ Complete and Deployed  
**Maintained**: Yes, active development
